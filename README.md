# üß™ Laboratorio 4: Explicando modelos con SHAP

Este laboratorio forma parte del curso de **Responsable AI** y tiene como objetivo aplicar la librer√≠a [SHAP](https://shap.readthedocs.io/) para **interpretar las decisiones de un modelo de visi√≥n por computadora**.  

Utilizamos el modelo **MobileNetV2** preentrenado en *ImageNet* y el explicador **Partition** de SHAP para generar explicaciones visuales que muestran qu√© regiones de la imagen influyen en las predicciones.

---

## üéØ Objetivos
- Cargar un modelo de clasificaci√≥n de im√°genes preentrenado (MobileNetV2).
- Realizar predicciones sobre un conjunto de im√°genes de prueba.
- Generar explicaciones con SHAP utilizando el explainer **Partition**.
- Visualizar las regiones relevantes mediante *heatmaps* superpuestos en las im√°genes.
- Reflexionar sobre el comportamiento del modelo: aciertos, errores y posibles sesgos.

---

## üìÇ Contenido
El laboratorio est√° organizado de la siguiente forma:

1. **Carga del modelo**
   - MobileNetV2 con pesos preentrenados de *ImageNet*.
   - Definici√≥n de categor√≠as y normalizaci√≥n de datos.

2. **Selecci√≥n de im√°genes**
   - Se utilizan al menos 2‚Äì3 im√°genes de ejemplo (`avion.jpg`, `gallo.jpg`, `gorras.jpg`).

3. **Predicci√≥n**
   - El modelo genera probabilidades y top-5 de clases m√°s probables para cada imagen.

4. **Explicaciones con SHAP**
   - Se aplica el `Partition explainer` para estimar la contribuci√≥n de cada p√≠xel/regi√≥n.
   - Se generan *heatmaps* con superposici√≥n manual sobre las im√°genes originales.

5. **Reflexi√≥n**
   - Se analiza si las √°reas resaltadas coinciden con los objetos principales.
   - Se estudia si el modelo se enfoca en regiones relevantes.
   - Se interpretan los casos en los que el modelo se confunde.

---

## üõ†Ô∏è Dependencias

Antes de ejecutar el notebook, aseg√∫rate de instalar las dependencias necesarias.  
Puedes hacerlo directamente con el archivo **requirements.txt** incluido en este repositorio:

```bash
pip install -r requirements.txt

